##### sdc.conf
##### Sink 1 = store unprocessed data to HDFS
##### Sink 2 = spark 



##### Name of the Component on this Agent 

sdc.sources = ws
sdc.sinks = HD spark 
sdc.channels = hdmem sparkmem

##### Describe / Configure the Source 

sdc.sources.ws.type = exec 
sdc.sources.ws.command = tail -F /var/log/httpd/access_log

##### Describe the Sinks 
sdc.sinks.hd.type = hdfs
sdc.sinks.hd.hdfs.path = hdfs://192.168.100.4:9000/flume_data
sdc.sinks.hd.hdfs.filePrefix = flume_demo
sdc.sinks.hd.hdfs.fileSuffix = .txt
sdc.sinks.hd.hdfs.rollInterval = 120
sdc.sinks.hd.hdfs.rollSize = 1048576
sdc.sinks.hd.hdfs.rollCount = 100
sdc.sinks.hd.hdfs.fileType = DataStream
sdc.sinks.spark.type = org.apache.spark.streaming.flume.sink.SparkSink
sdc.sinks.spark.hostname = 192.168.100.4
sdc.sinks.spark.port = 8123

#### USE CHANNEL
sdc.channels.hdmem.type = memory
sdc.channels.hdmem.capacity = 1000
sdc.cahnnels.hdmem.transactionCapacity = 100
sdc.channels.sparkmem.type = memory
sdc.channels.sparkmem.capacity = 1000
sdc.cahnnels.sparkmem.transactionCapacity = 100


#### BIND source sinks and channel 
sdc.sources.ws.channels = hdmem sparkmem
sdc.sinks.hd.channel = hdmem
sdc.sinks.spark.channel = sparkmem

